{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_matrix, axis):\n",
    "    \"\"\"\n",
    "    Normalizes the columns or rows of a 2d input_matrix so they sum to 1\n",
    "    \"\"\"\n",
    "\n",
    "    sums = input_matrix.sum(axis=axis)\n",
    "    # try:\n",
    "    #     assert (np.count_nonzero(sums)==np.shape(sums)[0]) # no set should sum to zero\n",
    "    # except Exception:\n",
    "    #     raise Exception(\"Error while normalizing. Sums to zero\")\n",
    "    if axis == 0:\n",
    "        new_matrix = np.divide(input_matrix, sums[np.newaxis:], out=np.zeros_like(input_matrix),\n",
    "                               where=sums[np.newaxis:]!=0)\n",
    "    else:\n",
    "        new_matrix = np.divide(input_matrix, sums[:, np.newaxis], out=np.zeros_like(input_matrix),\n",
    "                               where=sums[:, np.newaxis]!=0)\n",
    "    return new_matrix"
   ]
  },
  {
   "source": [
    "# Parameters\n",
    "## beta\n",
    "beta as k x |V| matrix that represents probability that word belongs to topic. initialize to 1/k for each word.\n",
    "\n",
    "## alpha\n",
    "probability of topic in the whole corpus represented as |k| size matrix\n",
    "\n",
    "## term doc matrix\n",
    "count of words in vocabulary for each document\n",
    "\n",
    "## pi\n",
    "word topic distribution for each document (what probability does word belong to topic)\n",
    "\n",
    "## gamma\n",
    "topic distribution for each document\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "k = 2 # number of topics\n",
    "v = 5 # number of words in vocabulary\n",
    "d = 3 # number of documents in corpus\n",
    "e_num_iter = 2 # number of iterations for e-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.array([1/k for i in range(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.full((k, v), 1/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.5, 0.5, 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, 0.5, 0.5]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_doc_matrix = np.random.randint(10, size=(d, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[8, 6, 5, 5, 2],\n",
       "       [7, 7, 7, 8, 6],\n",
       "       [1, 7, 4, 5, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "term_doc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = np.full((d, k), alpha)\n",
    "for i in range(d):\n",
    "    gamma[i] = gamma[i] + term_doc_matrix[i].sum()/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[13.5, 13.5],\n",
       "       [18. , 18. ],\n",
       "       [ 9. ,  9. ]])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([26, 35, 17])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# check with sum of words in each doc\n",
    "term_doc_matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(e_num_iter):\n",
    "    p = []\n",
    "    for j in range(d):\n",
    "        p.append(((beta * term_doc_matrix[j]).T * np.exp(digamma(gamma[j])-digamma(gamma[j].sum()))).T)\n",
    "    pi = np.array(p)\n",
    "    for j in range(d):\n",
    "        pi[j] = normalize(pi[j], 0)\n",
    "    # update gamma\n",
    "    for j in range(d):\n",
    "        gamma[j] = alpha + pi[j].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[3. , 3. ],\n",
       "       [3. , 3. ],\n",
       "       [2.5, 2.5]])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "gamma"
   ]
  },
  {
   "source": [
    "# alpha maximization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[3. , 3. ],\n",
       "       [3. , 3. ],\n",
       "       [2.5, 2.5]])"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import digamma, gamma as gamma_func\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_likelihood(alpha):\n",
    "    l_a = None\n",
    "    term_1 = d*np.log(gamma_func(alpha.sum()))\n",
    "    term_2 = d*np.log(gamma_func(alpha)).sum()\n",
    "    term_3 = 0\n",
    "    # term_3\n",
    "    for i in range(d): # of docs\n",
    "        term_3 = term_3 + ((alpha - 1) * (digamma(gamma[i]) - digamma(gamma[i].sum()))).sum()\n",
    "    l_a = (term_1 - term_2 + term_3) * -1 # to get maximum\n",
    "    return l_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      fun: -0.7288773730131606\n",
       " hess_inv: array([[4.95579503, 3.95579503],\n",
       "       [3.95579503, 4.95579503]])\n",
       "      jac: array([-8.34465027e-07, -8.34465027e-07])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 27\n",
       "      nit: 8\n",
       "     njev: 9\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([2.81097128, 2.81097128])"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "optimize.minimize(alpha_likelihood, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.064561963094976"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "alpha_likelihood(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.7288639206425014"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "alpha_likelihood(np.array([2.8, 2.8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.60716110110857"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "alpha_likelihood(np.array([4, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
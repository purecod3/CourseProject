{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Amazon MP3 Reviews\n",
    "Read file line by line to create list of values for each field. Then create a dictionary to turn into a dataframe\n",
    "- \"#####\" indicates a new record and will be used to update list index\n",
    "- do not assume that new record index is sequential\n",
    "- do not assume all records have the same fields and are in the same order\n",
    "\n",
    "## Review criteria\n",
    "Tried two different filters:\n",
    "- length of **filtered** review words (no stop words) < 50\n",
    "- length of **raw** review words (with stop words) < 50\n",
    "\n",
    "Decided to filter using **filtered** review words length instead of **raw**. Filtered yielded 16,780 records while raw yielded 24,409 records. When terms that occurred in less than 10 documents were removed, further filtering by length < 50 yielded ~16,200 records with either method. The target size of data is 16,680 records. \n",
    "\n",
    "To get as close as possible to original processed dataset, only 1 filter iteration for length will be applied using filtered words."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to hold data to be transformed to pandas dataframe\n",
    "amazon_data = {\n",
    "    'record_id':[],\n",
    "    'id':[],\n",
    "    'productId':[],\n",
    "    'standardName':[],\n",
    "    'productName':[],\n",
    "    'title':[],\n",
    "    'author':[],\n",
    "    'createDate':[],\n",
    "    'summary':[],\n",
    "    'fullText':[],\n",
    "    'rating':[],\n",
    "    'recommend':[],\n",
    "    'paid':[],\n",
    "    'helpfulNum':[],\n",
    "    'totalNum':[],\n",
    "    'commentNum':[],\n",
    "    'webHome':[],\n",
    "    'webUrl':[],\n",
    "    'htmlPath':[],\n",
    "    'textPath':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Last record is 55740\n"
     ]
    }
   ],
   "source": [
    "rec_num = 0\n",
    "# create dictionary with field names as keys and list of values from input file\n",
    "with open('amazon_mp3', 'r') as file:\n",
    "    # loop through file\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "         # end of file\n",
    "        if not line:\n",
    "            print('Last record is %d' % record_id)\n",
    "            # just in case all fields are not present\n",
    "            for k, v in amazon_data.items(): \n",
    "                if (k != 'record_id') & (len(v) != rec_num):\n",
    "                    amazon_data[k].append('')\n",
    "            break\n",
    "        # indicator for new record\n",
    "        if re.search('^#####', line): \n",
    "            record_id = int(re.search('\\d+',line).group())\n",
    "            amazon_data['record_id'].append(record_id) \n",
    "             # just in case all fields are not present in previous record\n",
    "            for k, v in amazon_data.items():\n",
    "                if (k != 'record_id') & (len(v) != rec_num):\n",
    "                    amazon_data[k].append('')\n",
    "            rec_num = rec_num + 1\n",
    "        # newline in between records\n",
    "        elif line == '\\n':\n",
    "            pass\n",
    "        # for each field in record\n",
    "        else:\n",
    "            try:\n",
    "                # remove punctuations\n",
    "                key = re.search('\\[(\\w+)\\]', line).group(1)\n",
    "                # create list of words\n",
    "                value = line.split(':',1)[1].strip()\n",
    "                # append value to list\n",
    "                amazon_data[key].append(value)\n",
    "            except:\n",
    "                print('Key not found for record %d' % record_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Expected length is 31000\n"
     ]
    }
   ],
   "source": [
    "# check lengths\n",
    "lengths=[]\n",
    "for k, v in amazon_data.items():\n",
    "    l = len(v)\n",
    "    lengths.append(l)\n",
    "    # print('Length of %s is %d' % (k, l))\n",
    "exp_len = max(lengths)\n",
    "print('Expected length is %d' % exp_len)\n",
    "# print any fields not matching the expect length\n",
    "for k, v in amazon_data.items():\n",
    "    if len(v) != exp_len:\n",
    "        print('Check %s as it is missing %d entries' % (k, exp_len-len(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from dictionary\n",
    "amazon_reviews_df = pd.DataFrame.from_dict(amazon_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stop words\n",
    "with open('stopwords.txt') as file:\n",
    "    stop_words_list = [word for word in file.read().splitlines()]\n",
    "\n",
    "def get_review_data(review):\n",
    "    '''\n",
    "    returns list of words not in stop words with punctuations removed and length of raw review\n",
    "    input: string\n",
    "    output: list of words \n",
    "    '''\n",
    "    review_wo_punc = re.sub(r'[^\\w\\s]', '', review)\n",
    "    review_words = review_wo_punc.lower().split()\n",
    "    raw_review_length = len(review_words)\n",
    "    review_data = [word.lower() for word in review_words if word.lower() not in stop_words_list]\n",
    "    filtered_review_length = len(review_data)\n",
    "    return review_data, filtered_review_length, raw_review_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get review data as list of words from review\n",
    "amazon_reviews_df['review_data'] = \\\n",
    "    amazon_reviews_df['fullText'].apply(lambda x: get_review_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reviews with more than 50 words in raw review: 24409\n"
     ]
    }
   ],
   "source": [
    "# alternative to filtering by raw review word count yielded more records\n",
    "raw_review_count = len(amazon_reviews_df[amazon_reviews_df['review_data'].str[2] >= 50])\n",
    "print('Reviews with more than 50 words in raw review: %d' % raw_review_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reviews with more than 50 words in filtered review: 16780\n"
     ]
    }
   ],
   "source": [
    "# will filter instead with filtered words (no stop words)\n",
    "amazon_reviews_df = amazon_reviews_df[amazon_reviews_df['review_data'].str[1] >= 50]\n",
    "print('Reviews with more than 50 words in filtered review: %d' % len(amazon_reviews_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dictionary with doc counts for each term\n",
    "term_doc_counts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in amazon_reviews_df.iterrows():\n",
    "    for w in row['review_data'][0]:\n",
    "        if w in term_doc_counts.keys():\n",
    "            term_doc_counts[w] = term_doc_counts[w] + 1\n",
    "        else:\n",
    "            term_doc_counts[w] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build list of terms to keep which are in at least 10 reviews\n",
    "terms_to_keep = dict(filter(lambda x: x[1] >= 10, term_doc_counts.items())).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Terms to vocabulary: 8637\n"
     ]
    }
   ],
   "source": [
    "# total terms\n",
    "print('Terms to vocabulary: %d' % len(terms_to_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only terms that are in at least 10 reviews\n",
    "amazon_reviews_df['review_words'] = amazon_reviews_df['review_data'].apply(lambda x: [w for w in x[0] if w in terms_to_keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "If second filter on length of review were applied, then record count would be: 16257\n"
     ]
    }
   ],
   "source": [
    "amazon_reviews_df['review_words_count'] = amazon_reviews_df['review_words'].apply(lambda x: len(x))\n",
    "two_filter_count = len(amazon_reviews_df[amazon_reviews_df['review_words_count'] >= 50])\n",
    "print('If second filter on length of review were applied,',\n",
    "      'then record count would be: %d' % two_filter_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16780"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# check if maybe filtering for rating too\n",
    "len(amazon_reviews_df[amazon_reviews_df['rating'] > ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['author', 'commentNum', 'createDate', 'fullText', 'helpfulNum',\n",
       "       'htmlPath', 'id', 'paid', 'productId', 'productName', 'rating',\n",
       "       'recommend', 'record_id', 'standardName', 'summary', 'textPath',\n",
       "       'title', 'totalNum', 'webHome', 'webUrl', 'review_data', 'review_words',\n",
       "       'review_words_count'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "amazon_reviews_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_reviews_df[['review_words','rating']].to_pickle('processed_amazon_reviews.pkl')"
   ]
  }
 ]
}